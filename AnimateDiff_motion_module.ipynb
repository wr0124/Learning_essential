{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm6xrdLYDdiRMorKB3f/WC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wr0124/Learning_essential/blob/main/AnimateDiff_motion_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoaP5zGHJPuj",
        "outputId": "30a44eb2-46e8-4d9f-d839-1037c69fc4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "WbDAvycIJbSA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(2, 3, 4, 2, 2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjgPVwAQJdsQ",
        "outputId": "52a1931d-1a64-4383-e580-495f3ec01b6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[[ 1.4563, -0.1745],\n",
            "           [-1.9305, -0.6525]],\n",
            "\n",
            "          [[-0.2448, -0.5148],\n",
            "           [-1.0070, -1.1509]],\n",
            "\n",
            "          [[ 0.8268,  0.8601],\n",
            "           [ 1.0506,  2.1072]],\n",
            "\n",
            "          [[-0.0615, -0.5769],\n",
            "           [ 0.4600, -0.2355]]],\n",
            "\n",
            "\n",
            "         [[[-1.6677,  0.6653],\n",
            "           [ 0.7922,  1.5480]],\n",
            "\n",
            "          [[ 2.3729, -0.0524],\n",
            "           [-1.1576,  1.6254]],\n",
            "\n",
            "          [[ 0.9990, -0.6284],\n",
            "           [-0.4289, -0.8202]],\n",
            "\n",
            "          [[ 0.4457, -0.5164],\n",
            "           [-0.7976,  1.1081]]],\n",
            "\n",
            "\n",
            "         [[[ 1.7992, -0.9455],\n",
            "           [ 0.1406, -0.1120]],\n",
            "\n",
            "          [[ 0.3925, -0.3140],\n",
            "           [ 0.0042, -0.0285]],\n",
            "\n",
            "          [[-0.1334,  1.2930],\n",
            "           [ 0.7025,  0.6880]],\n",
            "\n",
            "          [[-1.8323,  0.1044],\n",
            "           [-0.6214, -0.1715]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.5735, -0.0211],\n",
            "           [-0.9169, -2.7385]],\n",
            "\n",
            "          [[-1.2171,  0.8684],\n",
            "           [ 0.8424, -0.2886]],\n",
            "\n",
            "          [[ 1.0189, -0.2857],\n",
            "           [ 0.0287,  1.4488]],\n",
            "\n",
            "          [[ 1.1815, -0.3659],\n",
            "           [ 1.3223, -0.2590]]],\n",
            "\n",
            "\n",
            "         [[[ 1.1736,  0.2450],\n",
            "           [-0.5263, -0.4896]],\n",
            "\n",
            "          [[-1.3127, -1.1079],\n",
            "           [ 0.9501,  1.5127]],\n",
            "\n",
            "          [[-0.7202,  0.6042],\n",
            "           [-2.5897, -0.4155]],\n",
            "\n",
            "          [[ 0.7657, -0.5371],\n",
            "           [ 0.4554, -0.6479]]],\n",
            "\n",
            "\n",
            "         [[[-1.1635,  1.3607],\n",
            "           [-0.0762,  0.9405]],\n",
            "\n",
            "          [[-1.2969, -0.4958],\n",
            "           [-1.2579, -1.0680]],\n",
            "\n",
            "          [[-0.3474,  0.6884],\n",
            "           [ 0.2013, -0.4096]],\n",
            "\n",
            "          [[-1.7281,  1.0856],\n",
            "           [ 1.5809,  0.1019]]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class InflatedConv3d(nn.Conv2d):\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        video_length = x.shape[2]\n",
        "        print(video_length)\n",
        "        x = rearrange(x, \"b c f h w -> (b f) c h w\")\n",
        "        print(x.shape)\n",
        "        x = super().forward(x)\n",
        "        print(x.shape)\n",
        "        x = rearrange(x, \"(b f) c h w -> b c f h w\", f=video_length)\n",
        "        print(x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RaqnVB3DJgnH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_in = InflatedConv3d(3, 32, kernel_size=3, padding=(1, 1))\n",
        "print(conv_in)\n",
        "output_tensor = conv_in (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVlOsUzKJiJ3",
        "outputId": "98c6d2b7-60a5-4602-c90f-f914131849c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InflatedConv3d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2, 3, 4, 2, 2])\n",
            "4\n",
            "torch.Size([8, 3, 2, 2])\n",
            "torch.Size([8, 32, 2, 2])\n",
            "torch.Size([2, 32, 4, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 PositionalEncoding"
      ],
      "metadata": {
        "id": "-Br1ezYUJyOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        dropout = 0.,\n",
        "        max_len = 24\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        print(\"position\",position)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        print(\"div_term\", div_term )\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        print(\"pe\", pe)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        print(\"pe\", pe)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        print(\"pe\", pe)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "Tlz2q8MmJ0Bg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "import torch\n",
        "\n",
        "# Assuming d_model=512, max_len=24\n",
        "pos_enc = PositionalEncoding(d_model=2, max_len=24)\n",
        "\n",
        "input_tensor = torch.randn(1, 10, 2)  # Input tensor of shape (batch_size=1, sequence_length=100, d_model=512)\n",
        "print(\"before add into pos_enc \", input_tensor)\n",
        "output_tensor = pos_enc(input_tensor)   # Output tensor after adding positional encoding\n",
        "\n",
        "print(\"after add into pos_enc\",output_tensor)  # Output shape will be (1, 100, 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cahR6KGJ3Ow",
        "outputId": "acdbfbee-58ac-4947-a030-9432f1ac571a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "position tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19],\n",
            "        [20],\n",
            "        [21],\n",
            "        [22],\n",
            "        [23]])\n",
            "div_term tensor([1.])\n",
            "pe tensor([[[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]]])\n",
            "pe tensor([[[ 0.0000,  0.0000],\n",
            "         [ 0.8415,  0.0000],\n",
            "         [ 0.9093,  0.0000],\n",
            "         [ 0.1411,  0.0000],\n",
            "         [-0.7568,  0.0000],\n",
            "         [-0.9589,  0.0000],\n",
            "         [-0.2794,  0.0000],\n",
            "         [ 0.6570,  0.0000],\n",
            "         [ 0.9894,  0.0000],\n",
            "         [ 0.4121,  0.0000],\n",
            "         [-0.5440,  0.0000],\n",
            "         [-1.0000,  0.0000],\n",
            "         [-0.5366,  0.0000],\n",
            "         [ 0.4202,  0.0000],\n",
            "         [ 0.9906,  0.0000],\n",
            "         [ 0.6503,  0.0000],\n",
            "         [-0.2879,  0.0000],\n",
            "         [-0.9614,  0.0000],\n",
            "         [-0.7510,  0.0000],\n",
            "         [ 0.1499,  0.0000],\n",
            "         [ 0.9129,  0.0000],\n",
            "         [ 0.8367,  0.0000],\n",
            "         [-0.0089,  0.0000],\n",
            "         [-0.8462,  0.0000]]])\n",
            "pe tensor([[[ 0.0000,  1.0000],\n",
            "         [ 0.8415,  0.5403],\n",
            "         [ 0.9093, -0.4161],\n",
            "         [ 0.1411, -0.9900],\n",
            "         [-0.7568, -0.6536],\n",
            "         [-0.9589,  0.2837],\n",
            "         [-0.2794,  0.9602],\n",
            "         [ 0.6570,  0.7539],\n",
            "         [ 0.9894, -0.1455],\n",
            "         [ 0.4121, -0.9111],\n",
            "         [-0.5440, -0.8391],\n",
            "         [-1.0000,  0.0044],\n",
            "         [-0.5366,  0.8439],\n",
            "         [ 0.4202,  0.9074],\n",
            "         [ 0.9906,  0.1367],\n",
            "         [ 0.6503, -0.7597],\n",
            "         [-0.2879, -0.9577],\n",
            "         [-0.9614, -0.2752],\n",
            "         [-0.7510,  0.6603],\n",
            "         [ 0.1499,  0.9887],\n",
            "         [ 0.9129,  0.4081],\n",
            "         [ 0.8367, -0.5477],\n",
            "         [-0.0089, -1.0000],\n",
            "         [-0.8462, -0.5328]]])\n",
            "before add into pos_enc  tensor([[[ 0.7217, -0.4176],\n",
            "         [-0.0635, -1.7032],\n",
            "         [-1.1382,  2.2960],\n",
            "         [-1.3770, -2.0384],\n",
            "         [-0.7935,  1.2046],\n",
            "         [-0.2539, -2.6256],\n",
            "         [ 1.1476,  0.3606],\n",
            "         [ 0.2231, -1.1476],\n",
            "         [-1.4578,  0.3250],\n",
            "         [-3.6394, -2.2904]]])\n",
            "after add into pos_enc tensor([[[ 0.7217,  0.5824],\n",
            "         [ 0.7780, -1.1629],\n",
            "         [-0.2289,  1.8798],\n",
            "         [-1.2358, -3.0284],\n",
            "         [-1.5503,  0.5510],\n",
            "         [-1.2128, -2.3419],\n",
            "         [ 0.8682,  1.3207],\n",
            "         [ 0.8801, -0.3937],\n",
            "         [-0.4684,  0.1795],\n",
            "         [-3.2273, -3.2015]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 CorssAttention"
      ],
      "metadata": {
        "id": "UW-r4UMQJ5k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import isfunction\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if isfunction(d) else d\n",
        "\n",
        "# Example 1\n",
        "value = 42\n",
        "result = default(value, 0)\n",
        "print(result)  # Output: 42\n",
        "\n",
        "# Example 2\n",
        "value = None\n",
        "result = default(value, \"default\")\n",
        "print(result)  # Output: \"default\"\n",
        "\n",
        "# Example 3\n",
        "value = \"\"\n",
        "result = default(value, \"default\")\n",
        "print(result)  # Output: \"\"\n",
        "\n",
        "# Example 4\n",
        "value = []\n",
        "result = default(value, [1, 2, 3])\n",
        "print(result)  # Output: []\n",
        "\n",
        "# Example 5\n",
        "value = {}\n",
        "result = default(value, {\"key\": \"value\"})\n",
        "print(result)  # Output: {}\n",
        "\n",
        "# Example 6\n",
        "value = None\n",
        "result = default(value, lambda: \"computed_default\")\n",
        "print(result)  # Output: \"computed_default\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O89LJsHGJ784",
        "outputId": "982482bd-1b22-479f-94be-ba1a12d0cfb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "default\n",
            "\n",
            "[]\n",
            "{}\n",
            "computed_default\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##https://github.com/huggingface/diffusers_all/blob/main/src/diffusers/models/attention.py\n",
        "\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, query_dim, context_dim=None, heads=8, dim_head=64, dropout=0.0):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        context_dim = default(context_dim, query_dim)\n",
        "\n",
        "        self.scale = dim_head**-0.5\n",
        "        self.heads = heads\n",
        "\n",
        "        self.to_q = nn.Linear(query_dim, inner_dim, bias=False)\n",
        "        self.to_k = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "        self.to_v = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(nn.Linear(inner_dim, query_dim), nn.Dropout(dropout))\n",
        "\n",
        "    def reshape_heads_to_batch_dim(self, tensor):\n",
        "        batch_size, seq_len, dim = tensor.shape\n",
        "        head_size = self.heads\n",
        "        tensor = tensor.reshape(batch_size, seq_len, head_size, dim // head_size)\n",
        "        tensor = tensor.permute(0, 2, 1, 3).reshape(batch_size * head_size, seq_len, dim // head_size)\n",
        "        return tensor\n",
        "\n",
        "    def reshape_batch_dim_to_heads(self, tensor):\n",
        "        batch_size, seq_len, dim = tensor.shape\n",
        "        head_size = self.heads\n",
        "        tensor = tensor.reshape(batch_size // head_size, head_size, seq_len, dim)\n",
        "        tensor = tensor.permute(0, 2, 1, 3).reshape(batch_size // head_size, seq_len, dim * head_size)\n",
        "        return tensor\n",
        "\n",
        "    def forward(self, x, context=None, mask=None):\n",
        "        batch_size, sequence_length, dim = x.shape\n",
        "\n",
        "        h = self.heads\n",
        "\n",
        "        q = self.to_q(x)\n",
        "        context = default(context, x)\n",
        "        k = self.to_k(context)\n",
        "        v = self.to_v(context)\n",
        "\n",
        "        q = self.reshape_heads_to_batch_dim(q)\n",
        "        k = self.reshape_heads_to_batch_dim(k)\n",
        "        v = self.reshape_heads_to_batch_dim(v)\n",
        "\n",
        "        sim = torch.einsum(\"b i d, b j d -> b i j\", q, k) * self.scale\n",
        "\n",
        "        if exists(mask):\n",
        "            mask = mask.reshape(batch_size, -1)\n",
        "            max_neg_value = -torch.finfo(sim.dtype).max\n",
        "            mask = mask[:, None, :].repeat(h, 1, 1)\n",
        "            sim.masked_fill_(~mask, max_neg_value)\n",
        "\n",
        "        # attention, what we cannot get enough of\n",
        "        attn = sim.softmax(dim=-1)\n",
        "\n",
        "        out = torch.einsum(\"b i j, b j d -> b i d\", attn, v)\n",
        "        out = self.reshape_batch_dim_to_heads(out)\n",
        "        return self.to_out(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "dG2HZv2jJ-vX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}